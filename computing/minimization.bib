
@article{1964-Powell-CJ-7-155,
    author = {Powell, M. J. D.},
    title = {An efficient method for finding the minimum of a function of several variables without calculating derivatives},
    journal = {Comput. J.},
    volume = {7},
    number = {2},
    pages = {155-162},
    year = {1964},
    month = {01},
    abstract = {A simple variation of the well-known method of minimizing a function of several variables by changing one parameter at a time is described. This variation is such that when the procedure is applied to a quadratic form, it causes conjugate directions to be chosen, so the ultimate rate of convergence is fast when the method is used to minimize a general function. A further variation completes the method, and its ensures that the convergence rate from a bad approximation to a minimum is always efficient. Practical applications of the procedure have proved to be very satisfactory, and numerical examples are given in which functions of up to twenty variables are minimized.},
    issn = {0010-4620},
    doi = {10.1093/comjnl/7.2.155},
    url = {https://doi.org/10.1093/comjnl/7.2.155},
    %eprint = {http://oup.prod.sis.lan/comjnl/article-pdf/7/2/155/959784/070155.pdf},
}

@article{1965-Nelder-CJ-7-308,
   author = {Nelder, J. A. and Mead, R.},
   title = {A {Simplex} Method for Function Minimization},
   journal = {Comput. J.},
   volume = {7},
   number = {4},
   pages = {308--313},
   year = {1965},
   month = {01},
   abstract = {A method is described for the minimization of a function of n variables, which depends on the comparison of function values at the (n + 1) vertices of a general simplex, followed by the replacement of the vertex with the highest value by another point. The simplex adapts itself to the local landscape, and contracts on to the final minimum. The method is shown to be effective and computationally compact. A procedure is given for the estimation of the Hessian matrix in the neighbourhood of the minimum, needed in statistical estimation problems.},
   issn = {0010-4620},
   doi = {10.1093/comjnl/7.4.308},
   url = {https://doi.org/10.1093/comjnl/7.4.308},
   %eprint = {http://oup.prod.sis.lan/comjnl/article-pdf/7/4/308/1013182/7-4-308.pdf},
}

@article{1970-Fletcher-CJ-13-317,
   author = {Fletcher, R.},
   title = {A new approach to variable metric algorithms},
   journal = {Comput. J.},
   volume = {13},
   number = {3},
   pages = {317--322},
   year = {1970},
   month = {01},
   abstract = {An approach to variable metric algorithms has been investigated in which the linear search sub-problem no longer becomes necessary. The property of quadratic termination has been replaced by one of monotonic convergence of the eigenvalues of the approximating matrix to the inverse hessian. A convex class of updating formulae which possess this property has been established, and a strategy has been indicated for choosing a member of the class so as to keep the approximation away from both singularity and unboundedness. A FORTRAN program has been tested extensively with encouraging results.},
   issn = {0010-4620},
   doi = {10.1093/comjnl/13.3.317},
   url = {https://doi.org/10.1093/comjnl/13.3.317},
   %eprint = {http://oup.prod.sis.lan/comjnl/article-pdf/13/3/317/988678/130317.pdf},
}

