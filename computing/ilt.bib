% Inverse Laplace Transform (ILT)

@article{1966-Morozon-DANSSR-167-510,
   author = "V. A. Morozov",
   title = "On the solution of functional equations by the method of regularization",
   journal = "Dokl. Akad. Nauk SSSR",
   year = "1966",
   volume = "167",
   number = "3",
   pages = "510--512",
   url = "http://mi.mathnet.ru/eng/dan/v167/i3/p510",
}

@article{1978-Craven-NM-31-377,
   author = "Craven, Peter and Wahba, Grace",
   year = "1978",
   month = "12",
   day = "01",
   title = "Smoothing Noisy Data with Spline Functions: Estimating the Correct Degree of Smoothing by the Method of Generalized Cross-Validation",
   journal = "Numer. Math.",
   pages = "377--403",
   volume = "31",
   number = "4",
   abstract = "Smoothing splines are well known to provide nice curves which smooth discrete, noisy data. We obtain a practical, effective method for estimating the optimum amount of smoothing from the data. Derivatives can be estimated from the data by differentiating the resulting (nearly) optimally smoothed spline.",
   issn = "0945-3245",
   url = "https://doi.org/10.1007/BF01404567",
   doi = "10.1007/BF01404567",
}

@article{1979-Davies-JCP-33-1,
   title = "Numerical inversion of the {Laplace} transform: a survey and comparison of methods",
   journal = "J. Comput. Phys.",
   volume = "33",
   number = "1",
   pages = "1--32",
   year = "1979",
   issn = "0021-9991",
   doi = "10.1016/0021-9991(79)90025-1",
   url = "http://www.sciencedirect.com/science/article/pii/0021999179900251",
   author = "Brian Davies and Brian Martin",
   abstract = "A large number of different methods for numerically inverting the Laplace transform are tested and evaluated according to the criteria of applicability to actual inversion problems, applicability to various types of functions, numerical accuracy, computational efficiency, and ease of programming and implementation. The methods are presented briefly and classified theoretically into methods which compute a sample, methods which expand f(t) in exponential functions, methods based on Gaussian quadrature, methods based on a bilinear transformation, and methods based on Fourier series. Extensive results are presented, especially on the numerical accuracy of the methods on a set of 16 test functions. The main conclusion is that for attaining high accuracy on a wide range of test functions, the use of Laguerre polynomials is most successful, while methods based on Chebyshev polynomials and on accelerated convergence of a Fourier series are both quite good. However, no single method gives optimum results for all purposes and all occasions; the results obtained in this comparison give some idea of which methods are likely to be suitable for special problems and circumstances."
}

@article{1981-Butler-SIAMJNMA-18-381,
   author = {Butler, J. P. and Reeds, J. A. and Dawson, S. V.},
   title = {Estimating Solutions of First Kind Integral Equations with Nonnegative Constraints and Optimal Smoothing},
   journal = {SIAM J. Numer. Anal.},
   volume = {18},
   number = {3},
   pages = {381--397},
   year = {1981},
   doi = {10.1137/0718025},
   URL = {https://doi.org/10.1137/0718025},
   %eprint = {https://doi.org/10.1137/0718025}
}

@article{1983-Varah-SIAMJSSC-4-164,
   author = {Varah, J. M.},
   title = {Pitfalls in the Numerical Solution of Linear Ill-Posed Problems},
   journal = {SIAM J. Sci. Stat. Comput.},
   volume = {4},
   number = {2},
   pages = {164--176},
   year = {1983},
   doi = {10.1137/0904012},
   URL = {https://doi.org/10.1137/0904012},
   %eprint = {https://doi.org/10.1137/0904012}
}

@article{1984-Honig-JCAM-10-113,
   title = "A method for the numerical inversion of {Laplace} transforms",
   journal = "J. Comput. Appl. Math.",
   volume = "10",
   number = "1",
   pages = "113--132",
   year = "1984",
   issn = "0377-0427",
   doi = "10.1016/0377-0427(84)90075-X",
   url = "http://www.sciencedirect.com/science/article/pii/037704278490075X",
   author = "G. Honig and U. Hirdes",
   abstract = "In this paper a numerical inversion method for Laplace transforms, based on a Fourier series expansion developed by Durbin [5], is presented. The disadvantage of the inversion methods of that type, the encountered dependence of discretization and truncation error on the free parameters, is removed by the simultaneous application of a procedure for the reduction of the discretization error, a method for accelerating the convergence of the Fourier series and a procedure that computes approximately the ‘best’ choice of the free parameters. Suitable for a given problem, the inversion method allows the adequate application of these procedures. Therefore, in a big range of applications a high accuracy can be achieved with only a few function evaluations of the Laplace transform. The inversion method is implemented as a FORTRAN subroutine."
}

@article{1990-Hansen-SIAMJSSC-11-503,
   author = {Hansen, Per Christian.},
   title = {Truncated Singular Value Decomposition Solutions to Discrete Ill-Posed Problems with Ill-Determined Numerical Rank},
   journal = {SIAM J. Sci. Stat. Comput.},
   volume = {11},
   number = {3},
   pages = {503--518},
   year = {1990},
   doi = {10.1137/0911028},
   URL = {https://doi.org/10.1137/0911028},
   %eprint = {https://doi.org/10.1137/0911028}
}

@article{1992-Hansen-SIAMR-34-561,
   author = {Hansen, Per Christian},
   title = {Analysis of Discrete Ill-Posed Problems by Means of the {L}-Curve},
   journal = {SIAM Rev.},
   volume = {34},
   number = {4},
   pages = {561--580},
   year = {1992},
   doi = {10.1137/1034115},
   URL = {https://doi.org/10.1137/1034115},
   %eprint = {https://doi.org/10.1137/1034115}
}

@article{1993-Hansen-SIAMJSC-14-1487,
   author = {Hansen, Per Christian. and O’Leary, Dianne Prost.},
   title = {The Use of the {L}-Curve in the Regularization of Discrete Ill-Posed Problems},
   journal = {SIAM J. Sci. Comput.},
   volume = {14},
   number = {6},
   pages = {1487--1503},
   year = {1993},
   doi = {10.1137/0914086},
   URL = {https://doi.org/10.1137/0914086},
   %eprint = {https://doi.org/10.1137/0914086}
}

@article{1994-Craig-CP-8-648,
   author = {Craig, I. J. D. and Thompson, A. M. and Thompson, William J.},
   title = {Practical Numerical Algorithms Why {Laplace} Transforms Are Difficult To Invert Numerically},
   journal = {Comput. Phys.},
   volume = {8},
   number = {6},
   pages = {648--653},
   year = {1994},
   doi = {10.1063/1.4823347},
   URL = {https://aip.scitation.org/doi/abs/10.1063/1.4823347},
   %eprint = {https://aip.scitation.org/doi/pdf/10.1063/1.4823347}
}

@book{1995-Lawson-SLSP,
   author = {Lawson, Charles L. and Hanson, Richard J.},
   title = {Solving Least Squares Problems},
   publisher = {Society for Industrial and Applied Mathematics},
   year = {1995},
   doi = {10.1137/1.9781611971217},
   address = {Philadelphia},
   %edition = {},
   URL = {https://epubs.siam.org/doi/abs/10.1137/1.9781611971217},
   %eprint = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611971217},
   series = {Classics in Applied Mathematics},
}

@article{1995-Fordham-JMRSA-113-139,
   title = "Imaging Multiexponential Relaxation in the {$(y, \log_{e} T_{1})$} Plane, with Application to Clay Filtration in Rock Cores",
   journal = "J. Magn. Reson., Ser. A",
   volume = "113",
   number = "2",
   pages = "139--150",
   year = "1995",
   issn = "1064-1858",
   doi = "10.1006/jmra.1995.1073",
   url = "http://www.sciencedirect.com/science/article/pii/S106418588571073X",
   author = "E. J. Fordham and A. Sezginer and L. D. Hall",
   abstract = "An improved algorithm for determining regularized relaxation time (T1) distributions from inversion-recovery data obtained from fluid-saturated natural porous media (sedimentary rocks), for which the T1 distribution may be interpreted as a distribution of pore sizes, is reviewed. Because the selection of an appropriate value for the regularization parameter is automatic, requiring no user intervention or subjective choices, the data processing can be routinely applied, pixel by pixel, to multiple relaxation-weighted imaging data. This is illustrated with inversion-recovery data resolved in one spatial dimension y, obtained from experiments on the depth filtration of clay in sedimentary rock cores. A new kind of image results, of mixed physical dimensions (the (y, logeT1) plane). These images reveal details of the clay filtration process not previously available from simple profiles of a mean T1, in addition to known artifacts arising from blunders in specimen assembly; in some cases information of interest can be resolved even in the presence of gross artifact. The clay filtration results indicate that although clear reductions in mean T1 result from invasion of the rock pores by suspended clay, significantly larger clay concentrations would be required to distort the overall T1 distribution sufficiently to confuse invaded large pores with small pores containing practically immobile fluid."
}

@book{1995-Tikhonov-NMSIPP,
   author = "Tikhonov, A. N. and Goncharsky, A. V. and Stepanov, V. V. and Yagola, A. G.",
   title = "Numerical Methods for the Solution of Ill-Posed Problems",
   year = "1995",
   publisher = "Springer",
   address = "Dordrecht",
   volume = "328",
   series = "Mathematics and Its Applications",
   isbn = "978-94-015-8480-7",
   doi = "10.1007/978-94-015-8480-7",
   url = "https://doi.org/10.1007/978-94-015-8480-7"
}

@article{1997-Golub-JCGS-6-1,
   author = {Golub, Gene H. and von Matt, Urs},
   title = {Generalized Cross-Validation for Large-Scale Problems},
   journal = {J. Comput. Graph. Stat.},
   volume = {6},
   number = {1},
   pages = {1--34},
   year  = {1997},
   publisher = {Taylor & Francis},
   doi = {10.1080/10618600.1997.10474725},
   URL = {https://www.tandfonline.com/doi/abs/10.1080/10618600.1997.10474725},
   %eprint = {https://www.tandfonline.com/doi/pdf/10.1080/10618600.1997.10474725},
   abstract = {Although generalized cross-validation is a popular tool for calculating a regularization parameter, it has been rarely applied to large-scale problems until recently. A major difficulty lies in the evaluation of the cross-validation function that requires the calculation of the trace of an inverse matrix. In the last few years stochastic trace estimators have been proposed to alleviate this problem. This article demonstrates numerical approximation techniques that further reduce the computational complexity. The new approach employs Gauss quadrature to compute lower and upper bounds on the cross-validation function. It only requires the operator form of the system matrix—that is, a subroutine to evaluate matrix-vector products. Thus, the factorization of large matrices can be avoided. The new approach has been implemented in MATLAB. Numerical experiments confirm the remarkable accuracy of the stochastic trace estimator. Regularization parameters are computed for ill-posed problems with 100, 1,000, and 10,000 unknowns.}
}

@article{1998-Wenjiang-JCGS-7-397,
   author = {Wenjiang J. Fu},
   title = {Penalized Regressions: The Bridge versus the Lasso},
   journal = {J. Comput. Graph. Stat.},
   volume = {7},
   number = {3},
   pages = {397--416},
   year  = {1998},
   publisher = {Taylor & Francis},
   doi = {10.1080/10618600.1998.10474784},
   URL = {https://amstat.tandfonline.com/doi/abs/10.1080/10618600.1998.10474784},
   %eprint = {https://amstat.tandfonline.com/doi/pdf/10.1080/10618600.1998.10474784},
   abstract = { Abstract Bridge regression, a special family of penalized regressions of a penalty function Σ|βj|γ with γ ≤ 1, considered. A general approach to solve for the bridge estimator is developed. A new algorithm for the lasso (γ = 1) is obtained by studying the structure of the bridge estimators. The shrinkage parameter γ and the tuning parameter λ are selected via generalized cross-validation (GCV). Comparison between the bridge model (γ ≤ 1) and several other shrinkage models, namely the ordinary least squares regression (λ = 0), the lasso (γ = 1) and ridge regression (γ = 2), is made through a simulation study. It is shown that the bridge regression performs well compared to the lasso and ridge regression. These methods are demonstrated through an analysis of a prostate cancer data. Some computational advantages and limitations are discussed.}
}

@article{1998-Neumaier-SIAMR-40-636,
   author = {Neumaier, Arnold},
   title = {Solving Ill-Conditioned and Singular Linear Systems: A Tutorial on Regularization},
   journal = {SIAM Rev.},
   volume = {40},
   number = {3},
   pages = {636--666},
   year = {1998},
   doi = {10.1137/S0036144597321909},
   URL = {https://doi.org/10.1137/S0036144597321909},
   %eprint = {https://doi.org/10.1137/S0036144597321909}
}

@book{1998-Hansen-RDDIPP,
   author = {Hansen, Per Christian.},
   title = {Rank-Deficient and Discrete Ill-Posed Problems: Numerical Aspects of Linear Inversion},
   publisher = {Society for Industrial and Applied Mathematics},
   year = {1998},
   doi = {10.1137/1.9780898719697},
   address = {Philadelphia},
   %edition = {},
   URL = {https://epubs.siam.org/doi/abs/10.1137/1.9780898719697},
   %eprint = {https://epubs.siam.org/doi/pdf/10.1137/1.9780898719697}
}

@article{1999-Dunn-JMR-140-153,
   title = "The Inversion of {NMR} Log Data Sets with Different Measurement Errors",
   journal = "J. Magn. Reson.",
   volume = "140",
   number = "1",
   pages = "153--161",
   year = "1999",
   issn = "1090-7807",
   doi = "10.1006/jmre.1999.1837",
   url = "http://www.sciencedirect.com/science/article/pii/S1090780799918372",
   author = "Keh-Jim Dunn and Gerald A. LaTorraca",
   abstract = "We present a composite-data processing method which simultaneously processes two or more data sets with different measurement errors. We examine the role of the noise level of the data in the singular value decomposition inversion process, the criteria for a proper cutoff, and its effect on the uncertainty of the solution. Examples of processed logs using the composite-data processing method are presented and discussed. The possible usefulness of the apparent T1/T2 ratio extracted from the logs is illustrated."
}

@article{2001-OLeary-SIAMJSC-23-1161,
   author = {O'Leary, Dianne P.},
   title = {Near-Optimal Parameters for {Tikhonov} and Other Regularization Methods},
   journal = {SIAM J. Sci. Comput.},
   volume = {23},
   number = {4},
   pages = {1161--1171},
   year = {2001},
   doi = {10.1137/S1064827599354147},
   URL = {https://doi.org/10.1137/S1064827599354147},
   %eprint = {https://doi.org/10.1137/S1064827599354147}
}

@article{2001-Kilmer-SIAMJMAA-22-1204,
   author = {Kilmer, Misha E. and O'Leary., Dianne P.},
   title = {Choosing Regularization Parameters in Iterative Methods for Ill-Posed Problems},
   journal = {SIAM J. Matrix Anal. Appl.},
   volume = {22},
   number = {4},
   pages = {1204--1221},
   year = {2001},
   doi = {10.1137/S0895479899345960},
   URL = {https://doi.org/10.1137/S0895479899345960},
   %eprint = {https://doi.org/10.1137/S0895479899345960}
}

@article{2002-Venkataramanan-IEEETSP-50-1017,
   author = {L. Venkataramanan and Yi-Qiao Song and M. D. Hurlimann},
   journal = {IEEE Trans. Signal Process.},
   title = {Solving {Fredholm} integrals of the first kind with tensor product structure in 2 and 2.5 dimensions},
   year = {2002},
   volume = {50},
   number = {5},
   pages = {1017-1026},
   abstract = {We present an efficient algorithm to solve a class of two- and 2.5-dimensional (2-D and 2.5-D) Fredholm integrals of the first kind with a tensor product structure and nonnegativity constraint on the estimated parameters of interest in an optimization framework. A zeroth-order regularization functional is used to incorporate a priori information about the smoothness of the parameters into the problem formulation. We adapt the Butler-Reeds-Dawson (1981) algorithm to solve this optimization problem in three steps. In the first step, the data are compressed using singular value decomposition (SVD) of the kernels. The tensor-product structure of the kernel is exploited so that the compressed data is typically a thousand fold smaller than the original data. This size reduction is crucial for fast optimization. In the second step, the constrained optimization problem is transformed to an unconstrained optimization problem in the compressed data space. In the third step, a suboptimal value of the smoothing parameter is chosen by the BRD method. Steps 2 and 3 are iterated until convergence of the algorithm. We demonstrate the performance of the algorithm on simulated data.},
   keywords = {Fredholm integral equations;optimisation;parameter estimation;tensors;data compression;singular value decomposition;inverse problems;Fredholm integrals solution;efficient algorithm;tensor product structure;nonnegativity constraint;parameter estimation;zeroth-order regularization functional;parameters smoothness;Butler-Reeds-Dawson algorithm;data compression;2D inversion problems;2.5D inversion problems;singular value decomposition;SVD;tensor-product structure;constrained optimization problem;unconstrained optimization problem;compressed data space;BRD method;algorithm convergence;simulated data;Tensile stress;Kernel;Density functional theory;Nuclear magnetic resonance;Constraint optimization;Random variables;Image restoration;Magnetic field measurement;Gaussian noise;Additive noise},
   doi = {10.1109/78.995059},
   ISSN = {1941-0476},
   month = {May},
}

@article{2002-Song-JMR-154-261,
   title = "{$T_{1} - T_{2}$} Correlation Spectra Obtained Using a Fast Two-Dimensional {Laplace} Inversion",
   journal = "J. Magn. Reson.",
   volume = "154",
   number = "2",
   pages = "261--268",
   year = "2002",
   issn = "1090-7807",
   doi = "10.1006/jmre.2001.2474",
   url = "http://www.sciencedirect.com/science/article/pii/S1090780701924747",
   author = "Y.-Q. Song and L. Venkataramanan and M. D. Hürlimann and M. Flaum and P. Frulla and C. Straley",
   abstract = "Spin relaxation is a sensitive probe of molecular structure and dynamics. Correlation of relaxation time constants, such as T1 and T2, conceptually similar to the conventional multidimensional spectroscopy, have been difficult to determine primarily due to the absense of an efficient multidimensional Laplace inversion program. We demonstrate the use of a novel computer algorithm for fast two-dimensional inverse Laplace transformation to obtain T1–T2 correlation functions. The algorithm efficiently performs a least-squares fit on two-dimensional data with a nonnegativity constraint. We use a regularization method to find a balance between the residual fitting errors and the known noise amplitude, thus producing a result that is found to be stable in the presence of noise. This algorithm can be extended to include functional forms other than exponential kernels. We demonstrate the performance of the algorithm at different signal-to-noise ratios and with different T1–T2 spectral characteristics using several brine-saturated rock samples."
}

@article{2002-Castellanos-ANM-43-359,
   title = "The triangle method for finding the corner of the {L}-curve",
   journal = "Appl. Numer. Math.",
   volume = "43",
   number = "4",
   pages = "359--373",
   year = "2002",
   issn = "0168-9274",
   doi = "10.1016/S0168-9274(01)00179-9",
   url = "http://www.sciencedirect.com/science/article/pii/S0168927401001799",
   author = "J. Longina Castellanos and Susana Gómez and Valia Guerra",
   keywords = "CG-method, Regularization, L-curve, Ill-conditioned matrices, Systems of linear equations",
   abstract = "The Conjugate Gradient Method (CG) has an intrinsic regularization property when applied to systems of linear equations with ill-conditioned matrices. This regularization property is specially useful when either the right-hand side or the coefficient matrix, or both are given with errors. The regularization parameter is the iteration number, and in order to find this parameter, the L-curve is used. Here we present a novel method to find the corner of the L-curve, that determines the regularizing iteration number. Numerical results on the collection of test problems [SIAM J. Sci. Comput. 16 (1995) 506–512] are given to illustrate the potentiality of the method."
}

@phdthesis{2011-OrozcoRodriguez-PhD,
   author = "Orozco Rodr\'{i}guez, Jos\'{e} Alberto", 
   title = "Regularization methods for inverse problems",
   school = "University of Minnesota",
   year = "2011",
   month = "3",
   address = "Minneapolis",
   url = "http://hdl.handle.net/11299/104604",
}

@article{2011-Bauer-MCS-81-1795,
   title = "Comparing parameter choice methods for regularization of ill-posed problems",
   journal = "Math. Comput. Simul.",
   volume = "81",
   number = "9",
   pages = "1795--1841",
   year = "2011",
   issn = "0378-4754",
   doi = "10.1016/j.matcom.2011.01.016",
   url = "http://www.sciencedirect.com/science/article/pii/S0378475411000607",
   author = "Frank Bauer and Mark A. Lukas",
   keywords = "Ill-posed problem, Inverse problem, Regularization parameter, Spectral cut-off regularization, Tikhonov regularization",
   abstract = "In the literature on regularization, many different parameter choice methods have been proposed in both deterministic and stochastic settings. However, based on the available information, it is not always easy to know how well a particular method will perform in a given situation and how it compares to other methods. This paper reviews most of the existing parameter choice methods, and evaluates and compares them in a large simulation study for spectral cut-off and Tikhonov regularization. The test cases cover a wide range of linear inverse problems with both white and colored stochastic noise. The results show some marked differences between the methods, in particular, in their stability with respect to the noise and its type. We conclude with a table of properties of the methods and a summary of the simulation results, from which we identify the best methods."
}

@article{2013-Berman-CMRPA-42-72,
   author = {Berman, Paula and Levi, Ofer and Parmet, Yisrael and Saunders, Michael and Wiesman, Zeev},
   title = {{Laplace} inversion of low-resolution {NMR} relaxometry data using sparse representation methods},
   journal = {Concepts Magn. Reson. Part A},
   volume = {42},
   number = {3},
   pages = {72--88},
   keywords = {low-resolution NMR, sparse reconstruction, L1 regularization, convex optimization},
   doi = {10.1002/cmr.a.21263},
   url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cmr.a.21263},
   %eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/cmr.a.21263},
   abstract = {ABSTRACT Low-resolution nuclear magnetic resonance (LR-NMR) relaxometry is a powerful tool that can be harnessed for characterizing constituents in complex materials. Conversion of the relaxation signal into a continuous distribution of relaxation components is an ill-posed inverse Laplace transform problem. The most common numerical method implemented today for dealing with this kind of problem is based on L2-norm regularization. However, sparse representation methods via L1 regularization and convex optimization are a relatively new approach for effective analysis and processing of digital images and signals. In this article, a numerical optimization method for analyzing LR-NMR data by including non-negativity constraints and L1 regularization and by applying a convex optimization solver PDCO, a primal-dual interior method for convex objectives, that allows general linear constraints to be treated as linear operators is presented. The integrated approach includes validation of analyses by simulations, testing repeatability of experiments, and validation of the model and its statistical assumptions. The proposed method provides better resolved and more accurate solutions when compared with those suggested by existing tools. © 2013 Wiley Periodicals, Inc. Concepts Magn Reson Part A 42A: 72–88, 2013.},
   year = {2013}
}

@article{2017-Fordham-DF-29-2,
   title = "What are, and what are not, Inverse {Laplace} Transforms",
   author = "Edmund J. Fordham and Lalitha Venkataramanan and Jonathan Mitchell and Andrea Valori",
   journal = "Diffus. Fundam.",
   volume = "29",
   pages = "2",
   numpages = "6",
   year = "2017",
   month = "09",
   url = "https://diffusion.uni-leipzig.de/pdf/volume29/diff_fund_29(2017)2.pdf",
}

@article{2018-Benning-AN-27-1,
   title = {Modern regularization methods for inverse problems},
   volume = {27},
   DOI = {10.1017/S0962492918000016},
   journal = {Acta Numer.},
   publisher = {Cambridge University Press},
   author = {Benning, Martin and Burger, Martin},
   year = {2018},
   pages = {1-–111},
}

